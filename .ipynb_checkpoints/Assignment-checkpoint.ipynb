{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from io import StringIO\n",
    "from html.parser import HTMLParser\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from unidecode import unidecode\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read warc file\n",
    "def readWARC(filename):\n",
    "    f = open(filename)\n",
    "    htmlDict = dict()\n",
    "    responselist = []\n",
    "    htmllist = []\n",
    "    response = \"\"\n",
    "    temp = \"\"\n",
    "    boolRestart  = False\n",
    "    boolResponse = False\n",
    "    boolContent = False\n",
    "    boolDoctype = False\n",
    "    for line in f:\n",
    "        if 'WARC/1.0' in line:\n",
    "            boolRestart  = True\n",
    "            boolContent = False\n",
    "            boolDoctype = False\n",
    "            if len(temp)>0:\n",
    "                responselist.append(response)\n",
    "                htmllist.append(temp)\n",
    "                htmlDict[response]=temp\n",
    "            temp=\"\"\n",
    "            response = \"\"\n",
    "        if 'WARC-Type: response' in line:\n",
    "            boolResponse = True\n",
    "        if boolResponse == True and boolRestart == True:\n",
    "            if 'WARC-Target-URI:' in line:\n",
    "                response = line.lstrip('WARC-Target-URI:').strip()\n",
    "                boolRestart = False\n",
    "                boolResponse = False\n",
    "        if 'Content-Type: text/html' in line:\n",
    "            boolContent = True\n",
    "            temp =\"\"\n",
    "        if boolContent == True:\n",
    "            if '<!DOCTYPE html>' in line:\n",
    "                boolDoctype = True\n",
    "            if boolDoctype == True:\n",
    "                temp+=line.strip()\n",
    "    return htmlDict,responselist,htmllist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#strip down html tags\n",
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.reset()\n",
    "        self.strict = False\n",
    "        self.convert_charrefs= True\n",
    "        self.text = StringIO()\n",
    "    def handle_data(self, d):\n",
    "        self.text.write(d+\" \")\n",
    "    def get_data(self):\n",
    "        return self.text.getvalue()\n",
    "\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes a list of words (ie. stopwords) from a tokenized list.\n",
    "def removeWords(listOfTokens, listOfWords):\n",
    "    return [token for token in listOfTokens if token not in listOfWords]\n",
    "\n",
    "# remove punctations\n",
    "def removePunctuations(listOfTokens):\n",
    "    test_joined=' '.join(listOfTokens)\n",
    "    test_punc_removed = [char for char in test_joined if char not in string.punctuation]\n",
    "    test_punc_removed_join = ''.join(test_punc_removed)\n",
    "    return [word for word in test_punc_removed_join.split()]\n",
    "\n",
    "# removes any words composed of less than 2\n",
    "def twoLetters(listOfTokens):\n",
    "    twoLetterWord = []\n",
    "    for token in listOfTokens:\n",
    "        if len(token) < 2 :\n",
    "            twoLetterWord.append(token)\n",
    "    return twoLetterWord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#format HTML\n",
    "def formatHTML(htmllist):\n",
    "    pattern1 = r\"(?is)(<script[^>]*>)(.*?)(</script>)\"\n",
    "    pattern2 = r\"(?is)(<style[^>]*>)(.*?)(</style>)\"\n",
    "    pattern3 = r\"(?is)(<title[^>]*>)(.*?)(</title>)\"\n",
    "    for i in range(len(htmllist)):\n",
    "\n",
    "        #remove script tags\n",
    "        htmllist[i] = re.sub(pattern1,'',htmllist[i])\n",
    "        #remove style tags\n",
    "        htmllist[i] = re.sub(pattern2,'',htmllist[i])\n",
    "        #remove title tag\n",
    "        htmllist[i] = re.sub(pattern3,'',htmllist[i])\n",
    "        #strip out html tags\n",
    "        htmllist[i]=strip_tags(htmllist[i])\n",
    "\n",
    "        #remove special characters and leave only words\n",
    "        htmllist[i]=re.sub('\\W_',' ', htmllist[i])\n",
    "\n",
    "        # removes numbers and words concatenated with numbers IE h4ck3r. Removes road names such as BR-381.\n",
    "        htmllist[i]=re.sub(\"\\S*\\d\\S*\",\" \", htmllist[i])\n",
    "\n",
    "        htmllist[i] = htmllist[i].replace(u'\\ufffd', '8')    # Replaces the ASCII 'ï¿½' symbol with '8'\n",
    "        htmllist[i] = htmllist[i].replace(',', '.')          # Replace commas with period for split\n",
    "        htmllist[i] = htmllist[i].replace('?', '.')          # Replace question marks with periods for split\n",
    "        htmllist[i] = htmllist[i].rstrip('\\n')               # Removes line breaks\n",
    "        htmllist[i] = htmllist[i].casefold()                 # Makes all letters lowercase\n",
    "        #htmllist[i] = htmllist[i].replace(u'\\xa0', u'')     # Replaces \\xa0 with ''\n",
    "\n",
    "        listOfTokens = word_tokenize(htmllist[i])\n",
    "        twoLetterWord = twoLetters(listOfTokens)\n",
    "        listOfTokens = removeWords(listOfTokens, twoLetterWord)\n",
    "\n",
    "        #listOfTokens = removePunctuations(listOfTokens)\n",
    "\n",
    "        htmllist[i]   = \" \".join(listOfTokens)\n",
    "        htmllist[i] = unidecode(htmllist[i])\n",
    "    return htmllist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a cleaned dict\n",
    "def cleanedDictCreator(htmllist, responselist):\n",
    "    domainDict = dict()\n",
    "    domainOnly =[]\n",
    "    for i in range(len(responselist)):\n",
    "        domain = urlparse(responselist[i]).netloc\n",
    "        domainOnly.append(domain)\n",
    "        domainDict[responselist[i]] = htmllist[i]\n",
    "    return domainDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dictonaries countrywise\n",
    "def countryDict(domainDict):\n",
    "    auDict = dict()\n",
    "    caDict =dict()\n",
    "    ukDict = dict()\n",
    "    auDomain =[]\n",
    "    caDomain =[]\n",
    "    ukDomain =[]\n",
    "    for k, v in domainDict.items():\n",
    "        temp = urlparse(k).netloc\n",
    "        if temp[len(temp)-3:]=='.au':\n",
    "            auDict[k]=v\n",
    "            auDomain.append(k)\n",
    "        elif temp[len(temp)-3:]=='.ca':\n",
    "            caDict[k]=v\n",
    "            caDomain.append(k)\n",
    "        elif temp[len(temp)-3:]=='.uk':\n",
    "            ukDict[k]=v\n",
    "            ukDomain.append(k)\n",
    "    return auDict, caDict,ukDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#positive and negative list creation\n",
    "def posNegListCreator(posText,negText):\n",
    "    positiveWords = [line.rstrip('\\n') for line in open(posText)]\n",
    "    negativeWords =[line.rstrip('\\n') for line in open(negText)]\n",
    "    return positiveWords,negativeWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find positive words in .au domains\n",
    "def auGenPosNeg(auDict,positiveWords,negativeWords):\n",
    "    pnDict = dict()\n",
    "    for k,v in auDict.items():\n",
    "        negativePage = 0\n",
    "        positivePage = 0\n",
    "        rawPositive=0\n",
    "        rawNegative=0\n",
    "        ratio = 0\n",
    "        pnArray =[]\n",
    "        lineList =auDict[k].split('.')\n",
    "        for i in range(len(lineList)):\n",
    "            wordList = lineList[i].split(' ')\n",
    "            positiveCount=0\n",
    "            negativeCount=0\n",
    "            for j in range(len(wordList)):\n",
    "                if wordList[j].strip() in positiveWords:\n",
    "                    positiveCount+=1\n",
    "                    rawPositive+=1\n",
    "                if wordList[j].strip() in negativeWords:\n",
    "                    negativeCount+=1\n",
    "                    rawNegative+=1\n",
    "            if negativeCount == 2:\n",
    "                positivePage+=1\n",
    "            elif positiveCount>0 and negativeCount==0:\n",
    "                positivePage+=1\n",
    "            elif negativeCount>0 and positiveCount==0:\n",
    "                negativePage+=1\n",
    "            elif negativeCount>positiveCount:\n",
    "                negativePage+=1\n",
    "            elif positiveCount>negativeCount:\n",
    "                positivePage+=1\n",
    "            elif positiveCount==negativeCount and positiveCount!=0:\n",
    "                positivePage+=1 \n",
    "        if rawNegative!=0:\n",
    "            ratio = float(rawPositive)/rawNegative\n",
    "        pnArray =[rawPositive,rawNegative,ratio,positivePage,negativePage]\n",
    "        pnDict[k]=pnArray\n",
    "    \n",
    "    posTot=0\n",
    "    negTot=0\n",
    "    count =0\n",
    "    ratio =0\n",
    "    for k,v in pnDict.items():\n",
    "        posTot += v[0]\n",
    "        negTot += v[1]\n",
    "        count+=1\n",
    "    if negTot!=0:\n",
    "        gen_pos = [posTot,negTot,float(posTot)/negTot,float(posTot)/count,float(negTot)/count]\n",
    "    else:\n",
    "        gen_pos = [posTot,negTot,None,float(posTot)/count,float(negTot)/count]\n",
    "    return gen_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auGovPosNeg(auDict,positiveWords,negativeWords):\n",
    "    pnDict = dict()\n",
    "    for k,v in auDict.items():\n",
    "        negativePage = 0\n",
    "        positivePage = 0\n",
    "        rawPositive=0\n",
    "        rawNegative=0\n",
    "        ratio = 0\n",
    "        pnArray =[]\n",
    "        lineList =auDict[k].split('.')\n",
    "        for i in range(len(lineList)):\n",
    "            if 'government' in lineList[i]:\n",
    "                wordList = lineList[i].split(' ')\n",
    "                positiveCount=0\n",
    "                negativeCount=0\n",
    "                for j in range(len(wordList)):\n",
    "                    if wordList[j].strip() in positiveWords:\n",
    "                        positiveCount+=1\n",
    "                        rawPositive+=1\n",
    "                    if wordList[j].strip() in negativeWords:\n",
    "                        negativeCount+=1\n",
    "                        rawNegative+=1\n",
    "                if negativeCount == 2:\n",
    "                    positivePage+=1\n",
    "                elif positiveCount>0 and negativeCount==0:\n",
    "                    positivePage+=1\n",
    "                elif negativeCount>0 and positiveCount==0:\n",
    "                    negativePage+=1\n",
    "                elif negativeCount>positiveCount:\n",
    "                    negativePage+=1\n",
    "                elif positiveCount>negativeCount:\n",
    "                    positivePage+=1\n",
    "                elif positiveCount==negativeCount and positiveCount!=0:\n",
    "                    positivePage+=1 \n",
    "        if rawNegative!=0:\n",
    "            ratio = float(rawPositive)/rawNegative\n",
    "        pnArray =[rawPositive,rawNegative,ratio,positivePage,negativePage]\n",
    "        pnDict[k]=pnArray\n",
    "    \n",
    "    posTot=0\n",
    "    negTot=0\n",
    "    count =0\n",
    "    ratio =0\n",
    "    for k,v in pnDict.items():\n",
    "        posTot += v[0]\n",
    "        negTot += v[1]\n",
    "        count+=1\n",
    "    if negTot!=0:\n",
    "        gov_pos = [posTot,negTot,float(posTot)/negTot,float(posTot)/count,float(negTot)/count]\n",
    "    else:\n",
    "        gov_pos = [posTot,negTot,None,float(posTot)/count,float(negTot)/count]\n",
    "    return gov_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find country counting\n",
    "def countryCounter(auDict,caDict,ukDict):\n",
    "    ausDict=dict()\n",
    "    canDict =dict()\n",
    "    unitedDict = dict()\n",
    "    totalWordsau=0\n",
    "    totalWordsca=0\n",
    "    totalWordsuk=0\n",
    "\n",
    "    for k,v in auDict.items():\n",
    "        ausCount=0\n",
    "        lineList =auDict[k].split('.')\n",
    "        for i in range(len(lineList)):\n",
    "            wordList = lineList[i].split(' ')\n",
    "            for j in range(len(wordList)):\n",
    "                if 'australia' in wordList[j].strip():\n",
    "                    ausCount+=1\n",
    "                totalWordsau+=1\n",
    "        ausDict[k]=ausCount\n",
    "\n",
    "    for k,v in caDict.items():\n",
    "        canCount=0\n",
    "        lineList =caDict[k].split('.')\n",
    "        for i in range(len(lineList)):\n",
    "            wordList = lineList[i].split(' ')\n",
    "            for j in range(len(wordList)):\n",
    "                if 'canada' in wordList[j].strip():\n",
    "                    canCount+=1\n",
    "                totalWordsca+=1\n",
    "        canDict[k]=canCount\n",
    "\n",
    "    for k,v in ukDict.items():\n",
    "        ukCount=0\n",
    "        lineList =ukDict[k].split('.')\n",
    "        for i in range(len(lineList)):\n",
    "            wordList = lineList[i].split(' ')\n",
    "            for j in range(len(wordList)):\n",
    "                if 'united kingdom' in wordList[j].strip():\n",
    "                    ukCount+=1\n",
    "                elif 'great britain' in wordList[j].strip():\n",
    "                    ukCount+=1\n",
    "                elif 'uk' in wordList[j].strip():\n",
    "                    ukCount+=1\n",
    "                totalWordsuk+=1\n",
    "        unitedDict[k]=ukCount\n",
    "    return ausDict,canDict,unitedDict,totalWordsau,totalWordsca,totalWordsuk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find percentages\n",
    "def percentageListCreator(ausDict,canDict,unitedDict,totalWordsau,totalWordsca,totalWordsuk):\n",
    "    auWords =0\n",
    "    for k,v in ausDict.items():\n",
    "        auWords+=v\n",
    "    caWords=0\n",
    "    for k,v in canDict.items():\n",
    "        caWords+=v\n",
    "    ukWords=0\n",
    "    for k,v in unitedDict.items():\n",
    "        ukWords+=v\n",
    "    percentageList =[float(auWords)/totalWordsau, float(caWords)/totalWordsca, float(ukWords)/totalWordsuk]\n",
    "    percentageList = [val*100 for val in percentageList]\n",
    "    return percentageList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find domain occurances\n",
    "def findauDomains(auDict):\n",
    "    countDict=dict()\n",
    "    for k,v in auDict.items():\n",
    "        temp = urlparse(k).netloc\n",
    "        if temp in countDict:\n",
    "            countDict[temp]+=1\n",
    "        else:\n",
    "            countDict[temp]=1\n",
    "    countList = []\n",
    "    for k,v in countDict.items():\n",
    "        tup=(k,v)\n",
    "        countList.append(tup)\n",
    "    return countList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main method\n",
    "def main(WARC_fname, positive_words_fname, negative_words_fname):\n",
    "    htmlDict,responselist,htmllist = readWARC(WARC_fname)\n",
    "    htmllist = formatHTML(htmllist)\n",
    "    domainDict = cleanedDictCreator(htmllist, responselist)\n",
    "    auDict,caDict,ukDict = countryDict(domainDict)\n",
    "    positiveWords,negativeWords = posNegListCreator(positive_words_fname,negative_words_fname)\n",
    "    \n",
    "    gen_pos = auGenPosNeg(auDict,positiveWords,negativeWords)\n",
    "    \n",
    "    gov_pos = auGovPosNeg(auDict,positiveWords,negativeWords)\n",
    " \n",
    "    ausDict,canDict,unitedDict,totalWordsau,totalWordsca,totalWordsuk = countryCounter(auDict,caDict,ukDict)\n",
    "    \n",
    "    pat = percentageListCreator(ausDict,canDict,unitedDict,totalWordsau,totalWordsca,totalWordsuk)\n",
    "    \n",
    "    top_links = findauDomains(auDict)\n",
    "    \n",
    "    return gen_pos,gov_pos,pat,top_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    gen_pos, gov_pos, pat, top_links=main('warc_sample_file.warc','positive_words.txt','negative_words.txt')\n",
    "    print(\"gen_pos: \",gen_pos)\n",
    "    print(\"gov_pos: \",gov_pos)\n",
    "    print(\"pat: \",pat)\n",
    "    print(\"top_links: \",top_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
