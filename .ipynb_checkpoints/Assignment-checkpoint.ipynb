{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import operator\n",
    "from io import StringIO\n",
    "from html.parser import HTMLParser\n",
    "import string\n",
    "from urllib.parse import urlparse\n",
    "#from unidecode import unidecode\n",
    "#from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read warc file\n",
    "def readWARC(filename):\n",
    "    f = open(filename)\n",
    "    htmlDict = dict()\n",
    "    responselist = []\n",
    "    htmllist = []\n",
    "    response = \"\"\n",
    "    temp = \"\"\n",
    "    boolRestart  = False\n",
    "    boolResponse = False\n",
    "    boolContent = False\n",
    "    boolDoctype = False\n",
    "    for line in f:\n",
    "        if 'WARC/1.0' in line:\n",
    "            boolRestart  = True\n",
    "            boolContent = False\n",
    "            boolDoctype = False\n",
    "            if len(temp)>0:\n",
    "                responselist.append(response)\n",
    "                htmllist.append(temp)\n",
    "                htmlDict[response]=temp\n",
    "            temp=\"\"\n",
    "            response = \"\"\n",
    "        if 'WARC-Type: response' in line:\n",
    "            boolResponse = True\n",
    "        if boolResponse == True and boolRestart == True:\n",
    "            if 'WARC-Target-URI:' in line:\n",
    "                response = line.lstrip('WARC-Target-URI:').strip()\n",
    "                boolRestart = False\n",
    "                boolResponse = False\n",
    "        if 'Content-Type: text/html' in line:\n",
    "            boolContent = True\n",
    "            temp =\"\"\n",
    "        if boolContent == True:\n",
    "            if '<!DOCTYPE' in line or '<html' in line:\n",
    "                boolDoctype = True\n",
    "            if boolDoctype == True:\n",
    "                temp+=line.strip()\n",
    "    #print(htmllist[0])    \n",
    "    return htmlDict,responselist,htmllist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize the words\n",
    "def word_tokenize(sentence):\n",
    "    return [word.lower() for word in sentence.split()]\n",
    "\n",
    "# removes a list of unwanted words from a tokenized list\n",
    "def removeWords(listOfTokens, listOfWords):\n",
    "    return [token for token in listOfTokens if token not in listOfWords]\n",
    "\n",
    "# remove punctations\n",
    "def removePunctuations(listOfTokens):\n",
    "    test_joined=' '.join(listOfTokens)\n",
    "    punc = string.punctuation\n",
    "    punc = punc.replace('.','')\n",
    "    punc = punc.replace('+','')\n",
    "    punc = punc.replace('-','')\n",
    "    punc = punc.replace('*','')\n",
    "    \n",
    "    translator = re.compile('[%s]' % re.escape(punc))\n",
    "    test_punc_removed=translator.sub(' ', test_joined)\n",
    "    \n",
    "    test_punc_removed=re.sub(' +',' ',test_punc_removed).strip()\n",
    "    test_punc_removed_join=test_punc_removed\n",
    "\n",
    "    return [word for word in test_punc_removed_join.split()]\n",
    "\n",
    "# removes any words composed of less than 2\n",
    "def twoLetters(listOfTokens):\n",
    "    twoLetterWord = []\n",
    "    twoLetterList =['a','i','a+','am','an','as','at','by','do','go','he','hi','if','is','in','it','me','my','no',\n",
    "                    'of','ok','on','or','ox','pi','so','to''up','us','we']\n",
    "    for token in listOfTokens:\n",
    "        if (len(token) <= 2) and (token not in twoLetterList) :\n",
    "            twoLetterWord.append(token)\n",
    "    return twoLetterWord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#format HTML\n",
    "def formatHTML(htmllist):\n",
    "    pattern1 = r\"(?is)(<script[^>]*>)(.*?)(</script>)\"\n",
    "    pattern2 = r\"(?is)(<style[^>]*>)(.*?)(</style>)\"\n",
    "    pattern3 = r\"(?is)(<title[^>]*>)(.*?)(</title>)\"\n",
    "    for i in range(len(htmllist)):\n",
    "\n",
    "        #remove script tags\n",
    "        htmllist[i] = re.sub(pattern1,' ',htmllist[i])\n",
    "        #remove style tags\n",
    "        #htmllist[i] = re.sub(pattern2,' ',htmllist[i])\n",
    "        #remove title tag\n",
    "        #htmllist[i] = re.sub(pattern3,' ',htmllist[i])\n",
    "        #strip out html tags\n",
    "        htmllist[i] = re.sub(r'<.+?>', ' ', htmllist[i])\n",
    "        htmllist[i] = re.sub(r'&.+?;', ' ', htmllist[i])\n",
    "\n",
    "        #remove special characters and leave only words\n",
    "        htmllist[i]=re.sub('\\W_',' ', htmllist[i])\n",
    "\n",
    "        # removes numbers and words concatenated with numbers IE h4ck3r. Removes road names such as BR-381.\n",
    "        #htmllist[i]=re.sub(\"\\S*\\d\\S*\",\" \", htmllist[i])\n",
    "        htmllist[i]=''.join([t for t in htmllist[i] if not t.isdigit()])\n",
    "            \n",
    "        htmllist[i] = htmllist[i].replace(',', '.')          # Replace commas with period for split\n",
    "        htmllist[i] = htmllist[i].replace('?', '.')          # Replace question marks with periods for split\n",
    "        htmllist[i] = htmllist[i].rstrip('\\n')               # Removes line breaks\n",
    "        htmllist[i] = htmllist[i].casefold()                 # Makes all letters lowercase\n",
    "\n",
    "        #remove unwanted two letter words\n",
    "        listOfTokens = word_tokenize(htmllist[i])\n",
    "        twoLetterWord = twoLetters(listOfTokens)\n",
    "        listOfTokens = removeWords(listOfTokens, twoLetterWord)\n",
    "\n",
    "        listOfTokens = removePunctuations(listOfTokens)\n",
    "        \n",
    "        #remove two letter words after removing punctuations\n",
    "        twoLetterWord = twoLetters(listOfTokens)\n",
    "        listOfTokens = removeWords(listOfTokens, twoLetterWord)\n",
    "    \n",
    "        htmllist[i]   = \" \".join(listOfTokens)\n",
    "        \n",
    "    return htmllist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a cleaned dict\n",
    "def cleanedDictCreator(htmllist, responselist):\n",
    "    domainDict = dict()\n",
    "    domainOnly =[]\n",
    "    for i in range(len(responselist)):\n",
    "        domain = urlparse(responselist[i]).netloc\n",
    "        domainOnly.append(domain)\n",
    "        domainDict[responselist[i]] = htmllist[i]\n",
    "    return domainDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dictonaries countrywise\n",
    "def countryDict(domainDict):\n",
    "    auDict = dict()\n",
    "    caDict =dict()\n",
    "    ukDict = dict()\n",
    "    auDomain =[]\n",
    "    caDomain =[]\n",
    "    ukDomain =[]\n",
    "    for k, v in domainDict.items():\n",
    "        temp = urlparse(k).netloc\n",
    "        if temp[len(temp)-3:]=='.au':\n",
    "            auDict[k]=v\n",
    "            auDomain.append(k)\n",
    "        elif temp[len(temp)-3:]=='.ca':\n",
    "            caDict[k]=v\n",
    "            caDomain.append(k)\n",
    "        elif temp[len(temp)-3:]=='.uk':\n",
    "            ukDict[k]=v\n",
    "            ukDomain.append(k)\n",
    "    return auDict, caDict,ukDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#positive and negative list creation\n",
    "def posNegListCreator(posText,negText):\n",
    "    positiveWords = [line.rstrip('\\n') for line in open(posText)]\n",
    "    negativeWords =[line.rstrip('\\n') for line in open(negText)]\n",
    "    return positiveWords,negativeWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find positive and negative words in .au domains\n",
    "def auGenPosNeg(auDict,positiveWords,negativeWords):\n",
    "    pnDict = dict()\n",
    "    for k,v in auDict.items():\n",
    "        negativePage = 0\n",
    "        positivePage = 0\n",
    "        rawPositive=0\n",
    "        rawNegative=0\n",
    "        ratio = 0\n",
    "        pnArray =[]\n",
    "        lineList =auDict[k].split('.')\n",
    "        for i in range(len(lineList)):\n",
    "            wordList = lineList[i].split(' ')\n",
    "            positiveCount=0\n",
    "            negativeCount=0\n",
    "            for j in range(len(wordList)):        \n",
    "                if wordList[j].strip() in positiveWords:\n",
    "                    positiveCount+=1\n",
    "                    rawPositive+=1\n",
    "                if wordList[j].strip() in negativeWords:\n",
    "                    negativeCount+=1\n",
    "                    rawNegative+=1\n",
    "            if negativeCount == 2:\n",
    "                positivePage+=1\n",
    "            elif positiveCount>0 and negativeCount==0:\n",
    "                positivePage+=1\n",
    "            elif negativeCount>0 and positiveCount==0:\n",
    "                negativePage+=1\n",
    "            elif negativeCount>positiveCount:\n",
    "                negativePage+=0\n",
    "            elif positiveCount>negativeCount:\n",
    "                positivePage+=0\n",
    "            elif positiveCount==negativeCount and positiveCount!=0:\n",
    "                positivePage+=0 \n",
    "        if rawNegative!=0:\n",
    "            ratio = float(rawPositive)/rawNegative\n",
    "        pnArray =[rawPositive,rawNegative,ratio,positivePage,negativePage]\n",
    "        pnDict[k]=pnArray\n",
    "    \n",
    "    posTot=0\n",
    "    negTot=0\n",
    "    count =0\n",
    "    ratio =0\n",
    "    for k,v in pnDict.items():\n",
    "        posTot += v[0]\n",
    "        negTot += v[1]\n",
    "        count+=1\n",
    "    if negTot!=0:\n",
    "        gen_pos = [posTot,negTot,float(posTot)/negTot,float(posTot)/count,float(negTot)/count]\n",
    "    else:\n",
    "        gen_pos = [posTot,negTot,None,float(posTot)/count,float(negTot)/count]\n",
    "    return gen_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auGovPosNeg(auDict,positiveWords,negativeWords):\n",
    "    pnDict = dict()\n",
    "    for k,v in auDict.items():\n",
    "        negativePage = 0\n",
    "        positivePage = 0\n",
    "        rawPositive=0\n",
    "        rawNegative=0\n",
    "        ratio = 0\n",
    "        pnArray =[]\n",
    "        lineList =auDict[k].split('.')\n",
    "        for i in range(len(lineList)):\n",
    "            if 'government' in lineList[i]:\n",
    "                wordList = lineList[i].split(' ')\n",
    "                positiveCount=0\n",
    "                negativeCount=0\n",
    "                for j in range(len(wordList)):\n",
    "                    if wordList[j].strip() in positiveWords:\n",
    "                        positiveCount+=1\n",
    "                        rawPositive+=1\n",
    "                    if wordList[j].strip() in negativeWords:\n",
    "                        negativeCount+=1\n",
    "                        rawNegative+=1\n",
    "                if negativeCount == 2:\n",
    "                    positivePage+=1\n",
    "                elif positiveCount>0 and negativeCount==0:\n",
    "                    positivePage+=1\n",
    "                elif negativeCount>0 and positiveCount==0:\n",
    "                    negativePage+=1\n",
    "                elif negativeCount>positiveCount:\n",
    "                    negativePage+=0\n",
    "                elif positiveCount>negativeCount:\n",
    "                    positivePage+=0\n",
    "                elif positiveCount==negativeCount and positiveCount!=0:\n",
    "                    positivePage+=0 \n",
    "        if rawNegative!=0:\n",
    "            ratio = float(rawPositive)/rawNegative\n",
    "        pnArray =[rawPositive,rawNegative,ratio,positivePage,negativePage]\n",
    "        pnDict[k]=pnArray\n",
    "    \n",
    "    posTot=0\n",
    "    negTot=0\n",
    "    count =0\n",
    "    ratio =0\n",
    "    for k,v in pnDict.items():\n",
    "        posTot += v[3]\n",
    "        negTot += v[4]\n",
    "        count+=1\n",
    "    if negTot!=0:\n",
    "        gov_pos = [posTot,negTot,float(posTot)/negTot,float(posTot)/count,float(negTot)/count]\n",
    "    else:\n",
    "        gov_pos = [posTot,negTot,None,float(posTot)/count,float(negTot)/count]\n",
    "    return gov_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find country counting\n",
    "def countryCounter(auDict,caDict,ukDict):\n",
    "    ausDict=dict()\n",
    "    canDict =dict()\n",
    "    unitedDict = dict()\n",
    "    totalWordsau=0\n",
    "    totalWordsca=0\n",
    "    totalWordsuk=0\n",
    "\n",
    "    for k,v in auDict.items():\n",
    "        ausCount=0\n",
    "        lineList =auDict[k].split('.')\n",
    "        for i in range(len(lineList)):\n",
    "            wordList = lineList[i].split(' ')\n",
    "            for j in range(len(wordList)):\n",
    "                if 'australia' in wordList[j].strip():\n",
    "                    ausCount+=1\n",
    "                totalWordsau+=1\n",
    "        ausDict[k]=ausCount\n",
    "\n",
    "    for k,v in caDict.items():\n",
    "        canCount=0\n",
    "        lineList =caDict[k].split('.')\n",
    "        for i in range(len(lineList)):\n",
    "            wordList = lineList[i].split(' ')\n",
    "            for j in range(len(wordList)):\n",
    "                if 'canada' in wordList[j].strip():\n",
    "                    canCount+=1\n",
    "                totalWordsca+=1\n",
    "        canDict[k]=canCount\n",
    "\n",
    "    for k,v in ukDict.items():\n",
    "        ukCount=0\n",
    "        lineList =ukDict[k].split('.')\n",
    "        for i in range(len(lineList)):\n",
    "            wordList = lineList[i].split(' ')\n",
    "            for j in range(len(wordList)):\n",
    "                if 'united kingdom' in wordList[j].strip():\n",
    "                    ukCount+=1\n",
    "                elif 'great britain' in wordList[j].strip():\n",
    "                    ukCount+=1\n",
    "                elif 'uk' in wordList[j].strip():\n",
    "                    ukCount+=1\n",
    "                totalWordsuk+=1\n",
    "        unitedDict[k]=ukCount\n",
    "    return ausDict,canDict,unitedDict,totalWordsau,totalWordsca,totalWordsuk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find percentages\n",
    "def percentageListCreator(ausDict,canDict,unitedDict,totalWordsau,totalWordsca,totalWordsuk):\n",
    "    auWords =0\n",
    "    for k,v in ausDict.items():\n",
    "        auWords+=v\n",
    "    caWords=0\n",
    "    for k,v in canDict.items():\n",
    "        caWords+=v\n",
    "    ukWords=0\n",
    "    for k,v in unitedDict.items():\n",
    "        ukWords+=v\n",
    "    percentageList =[float(auWords)/totalWordsau, float(caWords)/totalWordsca, float(ukWords)/totalWordsuk]\n",
    "    percentageList = [val*100 for val in percentageList]\n",
    "    return percentageList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find domain occurances in the dict\n",
    "def findauDomains(auDict):\n",
    "    countDict=dict()\n",
    "    for k,v in auDict.items():\n",
    "        temp = urlparse(k).netloc\n",
    "        if temp in countDict:\n",
    "            countDict[temp]+=1\n",
    "        else:\n",
    "            countDict[temp]=1\n",
    "    cDict = dict(sorted(countDict.items(),key=operator.itemgetter(1),reverse=True))\n",
    "    countList=[]\n",
    "    for k,v in cDict.items():\n",
    "        tup=(k,v)\n",
    "        countList.append(tup)\n",
    "    return countList[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the domain occurances in the file\n",
    "def findauDomainsinFile(filename):\n",
    "    f = open(filename)\n",
    "    rawVal=[]\n",
    "    l=[]\n",
    "    for line in f:\n",
    "        if '<a' in line:\n",
    "            for templine in line.split('>'):\n",
    "                if 'href' in templine and '<a' in templine:\n",
    "                    for tline in templine.split('<a'):\n",
    "                        if 'href' in tline:\n",
    "                            tlinesplit=tline.split('=')\n",
    "                            for r in range(1,len(tlinesplit)):\n",
    "                                if 'href' in tlinesplit[r-1]:\n",
    "                                    s = re.search('https?://([A-Za-z_0-9.-]+).*',tlinesplit[r])\n",
    "                                    if s is not None:\n",
    "                                        if s:\n",
    "                                            rawVal.append(s.group(1))\n",
    "    for k in range(len(rawVal)):\n",
    "        temp =rawVal[k].split('.')\n",
    "        if temp[len(temp)-1].strip()=='au':\n",
    "            l.append(rawVal[k])\n",
    "    countDict=dict()\n",
    "    for i in range(len(l)):\n",
    "        if l[i] in countDict:\n",
    "            countDict[l[i]]+=1\n",
    "        else:\n",
    "            countDict[l[i]]=1\n",
    "    cDict = dict(sorted(countDict.items(),key=operator.itemgetter(1),reverse=True))\n",
    "    countList=[]\n",
    "    for k,v in cDict.items():\n",
    "        tup=(k,v)\n",
    "        countList.append(tup)\n",
    "    return countList[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main method\n",
    "def main(WARC_fname, positive_words_fname, negative_words_fname):\n",
    "    try:\n",
    "        htmlDict,responselist,htmllist = readWARC(WARC_fname)\n",
    "        htmllist = formatHTML(htmllist)\n",
    "        domainDict = cleanedDictCreator(htmllist, responselist)\n",
    "        auDict,caDict,ukDict = countryDict(domainDict)\n",
    "\n",
    "        positiveWords,negativeWords = posNegListCreator(positive_words_fname,negative_words_fname)\n",
    "\n",
    "        gen_pos = auGenPosNeg(auDict,positiveWords,negativeWords)\n",
    "\n",
    "        gov_pos = auGovPosNeg(auDict,positiveWords,negativeWords)\n",
    "\n",
    "        ausDict,canDict,unitedDict,totalWordsau,totalWordsca,totalWordsuk = countryCounter(auDict,caDict,ukDict)\n",
    "\n",
    "        pat = percentageListCreator(ausDict,canDict,unitedDict,totalWordsau,totalWordsca,totalWordsuk)\n",
    "\n",
    "        top_links =findauDomainsinFile(WARC_fname)\n",
    "        \n",
    "        return gen_pos,gov_pos,pat,top_links\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        return ([],[],[],dict())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen_pos:  [1349, 629, 2.1446740858505566, 31.372093023255815, 14.627906976744185]\n",
      "gov_pos:  [32, 11, 2.909090909090909, 0.7441860465116279, 0.2558139534883721]\n",
      "pat:  [0.5631899076368552, 0.33060453400503775, 0.2488157328101823]\n",
      "top_links:  [('www.industryupdate.com.au', 275), ('religionsforpeaceaustralia.org.au', 183), ('boundforsouthaustralia.history.sa.gov.au', 148), ('www.jcu.edu.au', 114), ('blogs.geelongcollege.vic.edu.au', 54)]\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    gen_pos, gov_pos, pat, top_links=main('warc_sample_file.warc','positive_words.txt','negative_words.txt')\n",
    "    print(\"gen_pos: \",gen_pos)\n",
    "    print(\"gov_pos: \",gov_pos)\n",
    "    print(\"pat: \",pat)\n",
    "    print(\"top_links: \",top_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST1\n",
    "\n",
    "#try:\n",
    "#    answer,b,c,d = main(\"warc_sample_file.warc\",\"positive_words.txt\",\"negative_words.txt\")\n",
    "#    sample_answer = [1238, 586, 2.1126, 26.913, 12.7391]\n",
    "#    print(a,b,c,d)\n",
    "#    flag = True\n",
    "#    if len(answer) != len(sample_answer):\n",
    "#        flag = False\n",
    "#    if abs(answer[0]-sample_answer[0]) > 1 or abs(answer[1]-sample_answer[1]) > 1 or abs(answer[2]-sample_answer[2]) > 0.001 or abs(answer[3]-sample_answer[3]) > 0.001 or abs(answer[4]-sample_answer[4]) > 0.001:\n",
    "#        flag = False\n",
    "#    print(flag)\n",
    "#except Exception as e:\n",
    "#    print(\"Error:\",str(e))\n",
    "#    print(False)\n",
    "\n",
    "#(RESULT = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST2\n",
    "\n",
    "# try:\n",
    "#    a,answer,c,d = main(\"warc_sample_file.warc\",\"positive_words.txt\",\"negative_words.txt\")\n",
    "#    sample_answer = [21, 13, 1.6154, 0.4565, 0.2826]\n",
    "#    flag = True\n",
    "#    if len(answer) != len(sample_answer):\n",
    "#       flag = False\n",
    "#    if abs(answer[0]-sample_answer[0]) > 1 or abs(answer[1]-sample_answer[1]) > 1 or abs(answer[2]-sample_answer[2]) > 0.001 or abs(answer[3]-sample_answer[3]) > 0.001 or abs(answer[4]-sample_answer[4]) > 0.001:\n",
    "#       flag = False\n",
    "#    print(flag)\n",
    "# except Exception as e:\n",
    "#    print(\"Error:\",str(e))\n",
    "#    print(False)\n",
    "\n",
    "#(RESULT = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST3\n",
    "\n",
    "# try:\n",
    "#    a,b,answer,d = main(\"warc_sample_file.warc\",\"positive_words.txt\",\"negative_words.txt\")\n",
    "#    sample_answer = [0.3421, 0.3186, 0.0995]\n",
    "#    flag = True\n",
    "#    if len(answer) != len(sample_answer):\n",
    "#       flag = False\n",
    "#    if abs(answer[0]-sample_answer[0]) > 0.001 or abs(answer[1]-sample_answer[1]) > 0.001 or abs(answer[2]-sample_answer[2]) > 0.001:\n",
    "#       flag = False\n",
    "#    print(flag)\n",
    "# except Exception as e:\n",
    "#    print(\"Error:\",str(e))\n",
    "#    print(False)\n",
    "\n",
    "#(RESULT = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('www.industryupdate.com.au', 275), ('religionsforpeaceaustralia.org.au', 183), ('boundforsouthaustralia.history.sa.gov.au', 148), ('www.jcu.edu.au', 114), ('blogs.geelongcollege.vic.edu.au', 54)]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#TEST4\n",
    "   \n",
    "#try:\n",
    "#    a,b,c,answer = main(\"warc_sample_file.warc\",\"positive_words.txt\",\"negative_words.txt\")\n",
    "#    sample_answer = [('www.industryupdate.com.au', 275), ('religionsforpeaceaustralia.org.au', 183), ('boundforsouthaustralia.history.sa.gov.au', 148), ('www.jcu.edu.au', 114), ('blogs.geelongcollege.vic.edu.au', 54)]\n",
    "#    flag = True\n",
    "#    if len(answer) != len(sample_answer):\n",
    "#        print(answer)\n",
    "#        flag = False\n",
    "#    for i in range(len(answer)):\n",
    "#        if answer[i][0] != sample_answer[i][0] or answer[i][1] != sample_answer[i][1]:\n",
    "#            flag = False\n",
    "#    print(flag)\n",
    "#except Exception as e:\n",
    "#    print(\"Error:\",str(e))\n",
    "#    print(False)\n",
    "   \n",
    "#(RESULT = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
